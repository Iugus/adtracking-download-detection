amostra2<-sample(filter(pop_data,carrier == "UA")$arr_delay,size = 1000)
amostra1 <- as.data.frame(sample1)
amostra2 <- as.data.frame(sample2)
erro_padrao_amostra1 = sd(amostra1$arr_delay) / sqrt(nrow(amostra1))
erro_padrao_amostra1
amostra1<-sample(filter(pop_data,carrier == "DL")$arr_delay,size = 1000)
amostra2<-sample(filter(pop_data,carrier == "UA")$arr_delay,size = 1000)
erro_padrao_amostra1 = sd(amostra1$arr_delay) / sqrt(nrow(amostra1))
amostra1 <- as.data.frame(sample1)
amostra2 <- as.data.frame(sample2)
View(amostra1)
erro_padrao_amostra1 = sd(amostra1$arr_delay,na.rm = T) / sqrt(nrow(amostra1))
erro_padrao_amostra1
# Limites inferior e superior
# 1.96 Ã© o valor de z score para 95% de confianÃ§a
a<-0.05/sqrt(nrow(amostra1))
0.05/sqrt(nrow(amostra1))
# Limites inferior e superior
limit_sup =max(amostra1$arr_delay)
limit_inf = min(amostra1$arr_delay)
# Limites inferior e superior
limit_sup =max(amostra1$arr_delay,na.rm=T)
limit_inf = min(amostra1$arr_delay,na.rm=T)
# Configurando o diretório de trabalho
# Coloque entre aspas o diretório de trabalho que você está usando no seu computador
# Não use diretórios com espaço no nome
setwd("C:/FCD/BigDataRAzure/Cap12")
# Carregando o pacote MASS
library(MASS)
# Importando os dados do dataset Boston
set.seed(101)
dados <- Boston
head(dados)
library(neuralnet)
hist(medv)
hist(dados$medv)
nn_test_v1 = neuralnet(medv~.,data = dados)
summary(nn_test_v1)
?neuralnet
# Criando a massa de dados (apesar de aleatória, y possui
# uma relação com os dados de x)
x <- seq(0, 100)
y <- 2 * x + 35
# Gerando uma distribuição normal
y1 <- y + rnorm(101, 0, 50)
y1
lines(x,y2)
modelo_lm_v1 = lm(y1 ~ x)
modelo_lm_v1
class(modelo_lm_v1)
# Capture os coeficentes
a=modelo_lm_v1$coefficients[1]
b=modelo_lm_v1$coefficients[2]
# Fórmula de Regressão
y2 <- a + b*x
lines(x,y2)
plot(x,y2,type="l")
lines(x,y2)
lines(x,y2,lwad =2)
lines(x,y2,lwd =2)
lines(x,y2,lwd =2)
lines(x,y2,lwd =2)
# Visualize a linha de regressão
plot
lines(x,y2,lwd =2)
# Visualize a linha de regressão
plot()
lines(x,y2,lwd =2)
# Visualize a linha de regressão
plot(x,y2)
lines(,lwd =2)
plot(x,y1)
lines(x,y2,lwd =2)
cor(df[c('G1','G2','G3','absences')])
#verificando colunas numericas
colunas_numericas = sapply(df,is.numeric)
install.packages("caret")
library(caret)
install.packages("randomForest")
library(randomForest)
library(datasets)
View(mtcars)
?createDataPartition
split <- crateDataPartition(y= mtcars$mpg, p=0.7, list=F)
split <- createDataPartition(y= mtcars$mpg, p=0.7, list=F)
dados_treino <- mtcars[split,]
dados_teste <-mtcars[-split,]
names(getModelInfo())
modelo_v1 <- train(mpg ~., data = dados_treino, method = "lm")
varImp(modelo_v1)
modelo_v1 <- train(mpg ~., data = dados_treino, method = "lm")
varImp(modelo_v1)
split <- createDataPartition(y= mtcars$mpg, p=0.7, list=F)
dados_treino <- mtcars[split,]
dados_teste <-mtcars[-split,]
modelo_v1 <- train(mpg ~., data = dados_treino, method = "lm")
varImp(modelo_v1)
modelo_v1 <- train(mpg ~ wt + hp + qsec + drat, data = dados_treino, method = "lm")
modelo_v1 <- train(mpg ~ wt + hp + qsec + drat, data = dados_treino, method = "rf")
modelo_v1 <- train(mpg ~ wt + hp + qsec + drat, data = dados_treino, method = "lm")
modelo_v2 <- train(mpg ~ wt + hp + qsec + drat, data = dados_treino, method = "rf")
library(twitteR)
availableTrendLocations()
avaliableTrendLocations()
avaliableTrendLocations()
closestTrendLocations(-46.84,-23.36)
registerTwitterOAuth("FuVfddRXT9mTIsP0AXBKoRJcm","fKQ6NF88TD6B956YM3h8B5PYWh1wjyz2dxq10voYXFIZyXPHWT")
dpt<-registerTwitterOAuth("FuVfddRXT9mTIsP0AXBKoRJcm","fKQ6NF88TD6B956YM3h8B5PYWh1wjyz2dxq10voYXFIZyXPHWT")
dpt<-getTwitterOAuth("FuVfddRXT9mTIsP0AXBKoRJcm","fKQ6NF88TD6B956YM3h8B5PYWh1wjyz2dxq10voYXFIZyXPHWT")
?setup_twitter_oauth
setup_twitter_oauth("x9vNTg7rpNnKGmUCkq9n5ZoIA","4zKf7yNZJ8zndrBskIZagmCCHyRdG8UdR7g3EQ9aCmXvpTovN5")
setup_twitter_oauth("x9vNTg7rpNnKGmUCkq9n5ZoIA","4zKf7yNZJ8zndrBskIZagmCCHyRdG8UdR7g3EQ9aCmXvpTovN5")
setup_twitter_oauth("x9vNTg7rpNnKGmUCkq9n5ZoIA","4zKf7yNZJ8zndrBskIZagmCCHyRdG8UdR7g3EQ9aCmXvpTovN5")
setup_twitter_oauth("x9vNTg7rpNnKGmUCkq9n5ZoIA","4zKf7yNZJ8zndrBskIZagmCCHyRdG8UdR7g3EQ9aCmXvpTovN5")
setup_twitter_oauth("x9vNTg7rpNnKGmUCkq9n5ZoIA","4zKf7yNZJ8zndrBskIZagmCCHyRdG8UdR7g3EQ9aCmXvpTovN5")
library(twitteR)
setup_twitter_oauth("x9vNTg7rpNnKGmUCkq9n5ZoIA","4zKf7yNZJ8zndrBskIZagmCCHyRdG8UdR7g3EQ9aCmXvpTovN5")
setup_twitter_oauth("1407114568577466370-tnJxIjnEwrGuzmwHbEl9AV7hxdkVeA","34kM2YgZgbAiw12a70vkyFipe4aQWWqTbyd4EkcAegJlE")
setup_twitter_oauth("1407114568577466370-tnJxIjnEwrGuzmwHbEl9AV7hxdkVeA","34kM2YgZgbAiw12a70vkyFipe4aQWWqTbyd4EkcAegJlE")
setup_twitter_oauth("VdziQuIJ6gnqVkTJHdigco1on","Gdfzzozjd92yxHtxYFvWXWFCLktyncOZnxhnmBLCN8owxhZXY4")
setup_twitter_oauth("1407114568577466370-Ktd2qhZEPUYYjT68rDUNSVscVyDgwd","C79BiLwxK8bc9qyX6LZWSOrXlxacl0H4rLDcYdrUbHyAp")
key<-"HjZkSGYuXAfPZcuiPixbOlhWN"
secret<-"KFUW5a5xxRXIwVmk3EsufOMR8bkPx5xpvvBIGfRc6BSW9Nr84P"
tokem<-"1407114568577466370-2S11z81Oc9gqJyhhXETOhI4CouyHhP"
tokensecret<- "wjlTIUUObluZoxG3GvagGqNASofZIdj25atttpQw3FZe8"
setup_twitter_oauth(key,secret,tokem,tokensecret)
result <- search_twitter_and_store("TecHome")
?register_db_backend
result <- search_twitter("TecHome")
result <- searchTwitter("TecHome")
View(result)
result <- searchTwitter("Tecverde")
View(result)
result <- searchTwitter("System76")
View(result)
result <- searchTwitter("System76", n= 10000)
View(result)
library(tm)
library(stringr)
library(plyr)
library(sentiment)
library(Rstem)
install.packages("C:/Cursos/Razure-1/Miniprojeto1/sentiment_0.2.tar.gz", repos = NULL, type = "source")
banco<-twListToDF(result)
View(banco)
corpusen<readDataframe(banco,"EN",NULL)
corpusen<-readDataframe(banco,"EN",NULL)
inspect(corpusen)
View(corpusen)
corpusen<-readDataframe(banco$text,"EN",NULL)
inspect(corpusen)
install("httr")
install.packages("httr")
library(httr)
install.packages("SnowballC")
Calc_Perf_measures(Tabela1,"all")
{
tp <- table1[1,1]
tf <- table1[2,2]
fp <- table1[2,1]
fn <- table1[1,2]
if (measure = "accuracy") {
accuracy <- (tp+tf)/(tp+tf+fp+fn)
return accuracy
} else {
if (measure = "recall")) {
recall <- tp/(tp+fn)
return recall
} else {
if (measure = "precision") {
precision <- tp/(tp+fp)
return precision
} else {
if (measure = "f-score") {
f-score <- 2*tp/(2*tp+fp+fn)
return f-score
} else {
if (measure = "all") {
f-score <- 2*tp/(2*tp+fp+fn)
precision <- tp/(tp+fp)
recall <- tp/(tp+fn)
accuracy <- (tp+tf)/(tp+tf+fp+fn)
calc_perf <- c(accuracy, recall, precision, f-score)
names(calc_perf)<- c("accuracy", "recall", "precision", "f-score")
}
}
}
}
}
}
Tabela1[1,1]
#importando dataset para treino
inicial_Data<- fread("work_data.csv")
setwd("C:/Cursos/Razure-1/Projeto1")
getwd()
#importando pacotes
library(tidyverse)
library(data.table)
library(lubridate)
#importando dataset para treino
inicial_Data<- fread("work_data.csv")
Changing_types <- function(dt){
fatores <- c("app","device","os","channel","is_attributed")
Char <- c("ip")
dt[,fatores] <- dt[,lapply(.SD,as.factor), .SDcols = fatores]
dt[,Char] <- dt[,lapply(.SD,as.character), .SDcols = Char]
return(dt)
}
Train_Data<-Changing_types(Train_Data)
Test_Data<-Changing_types(Test_Data)
Adding_dates_columns <- function(df){df %>%
mutate(Hour = hour(click_time),
day = day(click_time))
}
Train_Data <-Adding_dates_columns(Train_Data)
Test_Data <-Adding_dates_columns(Test_Data)
Train_rows <- sample(1:nrow(WorkData),nrow(WorkData)*0.7)
Train_Data <- WorkData[Train_rows,]
Test_Data <- WorkData[-Train_rows,]
#importando dataset para treino
workData<- fread("work_data.csv")
Changing_types <- function(dt){
fatores <- c("app","device","os","channel","is_attributed")
Char <- c("ip")
dt[,fatores] <- dt[,lapply(.SD,as.factor), .SDcols = fatores]
dt[,Char] <- dt[,lapply(.SD,as.character), .SDcols = Char]
return(dt)
}
Train_Data<-Changing_types(Train_Data)
Test_Data<-Changing_types(Test_Data)
Train_rows <- sample(1:nrow(WorkData),nrow(WorkData)*0.7)
Train_Data <- WorkData[Train_rows,]
Test_Data <- WorkData[-Train_rows,]
Train_rows <- sample(1:nrow(WorkData),nrow(WorkData)*0.7)
Train_Data <- WorkData[Train_rows,]
Test_Data <- WorkData[-Train_rows,]
WorkData
WorkData <-WorkData
View(workData)
setwd("C:/Cursos/Razure-1/Projeto1")
getwd()
#importando pacotes
library(tidyverse)
library(data.table)
library(lubridate)
#importando dataset para treino
inicial_Data<- fread("train.csv")
#verificando proporcoes de positivos do dataset
nrow(inicial_Data[is_attributed == 1,])/nrow(inicial_Data)
#Extraindo o dataset utilizando todos os registros de download possiveis
numero.downloads <- nrow(inicial_Data[is_attributed == 1,])
indices.download <- inicial_Data[,.I[is_attributed == 1]]
indices.negativo <- sample(inicial_Data[is_attributed == 0,.I],size = numero.downloads)
WorkData<- inicial_Data[c(indices.download,indices.negativo)]
rm(inicial_Data)
Train_rows <- sample(1:nrow(WorkData),nrow(WorkData)*0.7)
Train_Data <- WorkData[Train_rows,]
Test_Data <- WorkData[-Train_rows,]
?sample
#salvando o dataset
fwrite(WorkData, file = "Work_data.csv")
Changing_types <- function(dt){
fatores <- c("app","device","os","channel","is_attributed")
Char <- c("ip")
dt[,fatores] <- dt[,lapply(.SD,as.factor), .SDcols = fatores]
dt[,Char] <- dt[,lapply(.SD,as.character), .SDcols = Char]
return(dt)
}
Train_Data<-Changing_types(Train_Data)
Test_Data<-Changing_types(Test_Data)
Adding_dates_columns <- function(df){df %>%
mutate(Hour = hour(click_time),
day = day(click_time))
}
Train_Data <-Adding_dates_columns(Train_Data)
Test_Data <-Adding_dates_columns(Test_Data)
library(e1071)
library(kernlab)
library(kknn)
modelo1_naive <- naiveBayes(is_attributed ~ . -attributed_time, data = Train_Data)
predicao1 <- predict(modelo1_naive, Train_Data[,c(1:6,9:10)])
Tabela1 <- table(predicao1,Train_Data$is_attributed)
Calc_Perf_measures(Tabela1,"all")
Calc_Perf_measures <-function(table1,measure){
tp <- table1[1,1]
tf <- table1[2,2]
fp <- table1[2,1]
fn <- table1[1,2]
if (measure = "accuracy") {
accuracy <- (tp+tf)/(tp+tf+fp+fn)
return accuracy
} else {
if (measure = "recall")) {
recall <- tp/(tp+fn)
return recall
} else {
if (measure = "precision") {
precision <- tp/(tp+fp)
return precision
} else {
if (measure = "f-score") {
f-score <- 2*tp/(2*tp+fp+fn)
return f-score
} else {
if (measure = "all") {
f-score <- 2*tp/(2*tp+fp+fn)
precision <- tp/(tp+fp)
recall <- tp/(tp+fn)
accuracy <- (tp+tf)/(tp+tf+fp+fn)
calc_perf <- c(accuracy, recall, precision, f-score)
names(calc_perf)<- c("accuracy", "recall", "precision", "f-score")
}
}
}
}
}
}
Tabela1[1,1]
Tabela1[1,2]
Calc_Perf_measures <-function(table1,measure){
tp <- table1[1,1]
tf <- table1[2,2]
fp <- table1[2,1]
fn <- table1[1,2]
if (measure = "accuracy") {
accuracy <- (tp+tf)/(tp+tf+fp+fn)
return(accuracy)
} else {
if (measure = "recall") {
recall <- tp/(tp+fn)
return(recall)
} else {
if (measure = "precision") {
precision <- tp/(tp+fp)
return(precision)
} else {
if (measure = "f-score") {
f-score <- 2*tp/(2*tp+fp+fn)
return(f-score)
} else {
if (measure = "all") {
f-score <- 2*tp/(2*tp+fp+fn)
precision <- tp/(tp+fp)
recall <- tp/(tp+fn)
accuracy <- (tp+tf)/(tp+tf+fp+fn)
calc_perf <- c(accuracy, recall, precision, f-score)
names(calc_perf)<- c("accuracy", "recall", "precision", "f-score")
return(calc_perf)
}
}
}
}
}
}
Calc_Perf_measures <-function(table1,measure){
tp <- table1[1,1]
tf <- table1[2,2]
fp <- table1[2,1]
fn <- table1[1,2]
if (measure = "accuracy") {
accuracy <- (tp+tf)/(tp+tf+fp+fn)
return(accuracy)
} else {
if (measure = "recall") {
recall <- tp/(tp+fn)
return(recall)
} else {
if (measure = "precision") {
precision <- tp/(tp+fp)
return(precision)
} else {
if (measure = "f-score") {
f-score <- 2*tp/(2*tp+fp+fn)
return(f-score)
} else {
if (measure = "all") {
f-score <- 2*tp/(2*tp+fp+fn)
precision <- tp/(tp+fp)
recall <- tp/(tp+fn)
accuracy <- (tp+tf)/(tp+tf+fp+fn)
calc_perf <- c(accuracy, recall, precision, f-score)
names(calc_perf)<- c("accuracy", "recall", "precision", "f-score")
return(calc_perf)
}
}
}
}
}
}
Calc_Perf_measures <-function(table1,measure){
tp <- table1[1,1]
tf <- table1[2,2]
fp <- table1[2,1]
fn <- table1[1,2]
if (measure == "accuracy") {
accuracy <- (tp+tf)/(tp+tf+fp+fn)
return(accuracy)
} else {
if (measure == "recall") {
recall <- tp/(tp+fn)
return(recall)
} else {
if (measure == "precision") {
precision <- tp/(tp+fp)
return(precision)
} else {
if (measure == "f-score") {
f-score <- 2*tp/(2*tp+fp+fn)
return(f-score)
} else {
if (measure == "all") {
f-score <- 2*tp/(2*tp+fp+fn)
precision <- tp/(tp+fp)
recall <- tp/(tp+fn)
accuracy <- (tp+tf)/(tp+tf+fp+fn)
calc_perf <- c(accuracy, recall, precision, f-score)
names(calc_perf)<- c("accuracy", "recall", "precision", "f-score")
return(calc_perf)
}
}
}
}
}
}
Calc_Perf_measures(Tabela1,"all")
Calc_Perf_measures <-function(table1,measure){
tp <- table1[1,1]
tf <- table1[2,2]
fp <- table1[2,1]
fn <- table1[1,2]
if (measure == "accuracy") {
accuracy <- (tp+tf)/(tp+tf+fp+fn)
return(accuracy)
} else {
if (measure == "recall") {
recall <- tp/(tp+fn)
return(recall)
} else {
if (measure == "precision") {
precision <- tp/(tp+fp)
return(precision)
} else {
if (measure == "fscore") {
fscore <- 2*tp/(2*tp+fp+fn)
return(f-score)
} else {
if (measure == "all") {
fscore <- 2*tp/(2*tp+fp+fn)
precision <- tp/(tp+fp)
recall <- tp/(tp+fn)
accuracy <- (tp+tf)/(tp+tf+fp+fn)
calc_perf <- c(accuracy, recall, precision, f-score)
names(calc_perf)<- c("accuracy", "recall", "precision", "fscore")
return(calc_perf)
}
}
}
}
}
}
Calc_Perf_measures(Tabela1,"all")
Calc_Perf_measures <-function(table1,measure){
tp <- table1[1,1]
tf <- table1[2,2]
fp <- table1[2,1]
fn <- table1[1,2]
if (measure == "accuracy") {
accuracy <- (tp+tf)/(tp+tf+fp+fn)
return(accuracy)
} else {
if (measure == "recall") {
recall <- tp/(tp+fn)
return(recall)
} else {
if (measure == "precision") {
precision <- tp/(tp+fp)
return(precision)
} else {
if (measure == "fscore") {
fscore <- 2*tp/(2*tp+fp+fn)
return(f-score)
} else {
if (measure == "all") {
fscore <- 2*tp/(2*tp+fp+fn)
precision <- tp/(tp+fp)
recall <- tp/(tp+fn)
accuracy <- (tp+tf)/(tp+tf+fp+fn)
calc_perf <- c(accuracy, recall, precision, fscore)
names(calc_perf)<- c("accuracy", "recall", "precision", "fscore")
return(calc_perf)
}
}
}
}
}
}
Calc_Perf_measures(Tabela1,"all")
predicao_test <- predict(modelo1_naive, Test_Data[,c(1:6,9:10)])
tabela_test1 <- table(predicao_test,Test_Data$is_attributed)
Calc_Perf_measures(Tabela_test1,"all")
tabela_test1 <- table(predicao_test,Test_Data$is_attributed)
Calc_Perf_measures(tabela_test1,"all")
modelo1_svm <- svm(is_attributed ~ . -attributed_time,Train_Data, type = "C-classification")
modelo1_svm <- svm(is_attributed ~ . -attributed_time,Train_Data)
modelo1_svm <- svm(is_attributed ~ . -attributed_time,Train_Data, type = "C-classification", kernel = "linear")
modelo1_svm <- svm(is_attributed ~ . -attributed_time,Train_Data, type = "C-classification", kernel = "linear", scale = 3)
modelo1_svm <- svm(is_attributed ~ . -attributed_time,Train_Data, type = "C-classification", kernel = "linear", scale = 1)
modelo1_svm <- svm(is_attributed ~ . -attributed_time,Train_Data, type = "C-classification", kernel = "linear", scale = 0)
#testando algoritmo svm
matrix_train <- as.matrix(Train_Data)
modelo1_svm <- svm(is_attributed ~ . -attributed_time,matrix_train, type = "C-classification", kernel = "linear", scale = 0)
modelo1_knn <- train.kknn(is_attributed ~ . -attributed_time,Train_Data)
